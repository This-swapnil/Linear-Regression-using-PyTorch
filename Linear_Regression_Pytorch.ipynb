{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sck_3OWMo4fB",
        "outputId": "f5a6a1cd-20b4-4759-8e83-f527dc4030cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  6 09:54:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "cpx8cM50ppEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input_data\n",
        "input = np.array([[32,55,77],\n",
        "                  [31,75,57],\n",
        "                  [52,55,77],\n",
        "                  [22,100,87],\n",
        "                  [62,80,77],\n",
        "\n",
        "                  ], dtype='float32')"
      ],
      "metadata": {
        "id": "nGTQLGHLpxgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzfSejcvqax9",
        "outputId": "2496e5a6-d665-42d1-bd47-6bbcc0720e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.,  55.,  77.],\n",
              "       [ 31.,  75.,  57.],\n",
              "       [ 52.,  55.,  77.],\n",
              "       [ 22., 100.,  87.],\n",
              "       [ 62.,  80.,  77.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#target\n",
        "targets = np.array([[32,66],\n",
        "                    [52,76],\n",
        "                    [102,155],\n",
        "                    [32,26],\n",
        "                    [99,100],\n",
        "                    ], dtype='float32')"
      ],
      "metadata": {
        "id": "BZyirHbBqcJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddZMQyUZq2Su",
        "outputId": "6df52ce1-4638-4c4f-ad1e-49f328e5b197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.,  66.],\n",
              "       [ 52.,  76.],\n",
              "       [102., 155.],\n",
              "       [ 32.,  26.],\n",
              "       [ 99., 100.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq343M2uq3kZ",
        "outputId": "acb46a0a-d004-485f-faec-2ab0b87bb2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 32.,  55.,  77.],\n",
            "        [ 31.,  75.,  57.],\n",
            "        [ 52.,  55.,  77.],\n",
            "        [ 22., 100.,  87.],\n",
            "        [ 62.,  80.,  77.]])\n",
            "tensor([[ 32.,  66.],\n",
            "        [ 52.,  76.],\n",
            "        [102., 155.],\n",
            "        [ 32.,  26.],\n",
            "        [ 99., 100.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Weigts & biases\n",
        "\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2 , requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RloUxSiYr65L",
        "outputId": "9cc27d0e-5df1-4ddb-f2a4-f54f16b44d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0412,  1.2590, -1.2720],\n",
            "        [ 0.2609,  0.3343,  0.3251]], requires_grad=True)\n",
            "tensor([-1.4696,  0.8582], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "VXxaV70MtF54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmxkTW_Xuw6v",
        "outputId": "d871ceaa-f511-4e34-f3c7-336bfc96fe20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-28.8501,  52.6259],\n",
            "        [ 21.7295,  52.5479],\n",
            "        [-28.0267,  57.8434],\n",
            "        [ 14.6746,  68.3107],\n",
            "        [  3.8607,  68.8089]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8epgaljvAwK",
        "outputId": "948d9a5d-6ee3-4aff-9f32-3afe42ed3d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 32.,  66.],\n",
              "        [ 52.,  76.],\n",
              "        [102., 155.],\n",
              "        [ 32.,  26.],\n",
              "        [ 99., 100.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "\n",
        "def MSE(t1, t2):\n",
        "  diff = t1- t2\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "aOeT60tkvCz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute loss\n",
        "\n",
        "loss = MSE(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "przwqeQnvwef",
        "outputId": "ba4bedb5-cd94-459b-e8c3-fae678385a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4380.8979, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute gradient\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "wds5dyV2wEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zZWx5Zswfz1",
        "outputId": "56a85a1d-f8c3-4bfd-d49b-2cccc97ee82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0412,  1.2590, -1.2720],\n",
            "        [ 0.2609,  0.3343,  0.3251]], requires_grad=True)\n",
            "tensor([[-3185.3545, -4422.4385, -5051.1934],\n",
            "        [-1442.0281, -1220.4625, -1713.6630]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5   #w(new) = w(old) - learning_rate (dx/dw)\n",
        "  b -= b.grad * 1e-5"
      ],
      "metadata": {
        "id": "4vxppy2nwlv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEY56lfJyR8U",
        "outputId": "f1e8864a-234b-479d-9744-837880d89404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0730,  1.3033, -1.2215],\n",
            "        [ 0.2753,  0.3465,  0.3423]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMs_BEcR2EJ9",
        "outputId": "0866f93c-20a1-4478-fe16-f44a3fc9049f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)"
      ],
      "metadata": {
        "id": "qnptCU8xyfM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSE(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2spFbAJzDN1",
        "outputId": "7d3809b6-5a57-44f4-c12b-e4cf962aeb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3802.2559, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "n = 400\n",
        "for i in range(n):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(preds, targets)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5   #w(new) = w(old) - learning_rate (dx/dw)\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(f\"Epochs: {i}/{n} ---- Loss: {loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTRkTw5GzHfg",
        "outputId": "dd630590-29ca-453e-cdfb-da62f359a36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0/400 ---- Loss: 571.2599487304688\n",
            "Epochs: 1/400 ---- Loss: 569.7034912109375\n",
            "Epochs: 2/400 ---- Loss: 568.1566162109375\n",
            "Epochs: 3/400 ---- Loss: 566.6192626953125\n",
            "Epochs: 4/400 ---- Loss: 565.09130859375\n",
            "Epochs: 5/400 ---- Loss: 563.572998046875\n",
            "Epochs: 6/400 ---- Loss: 562.0638427734375\n",
            "Epochs: 7/400 ---- Loss: 560.5640869140625\n",
            "Epochs: 8/400 ---- Loss: 559.07373046875\n",
            "Epochs: 9/400 ---- Loss: 557.5924072265625\n",
            "Epochs: 10/400 ---- Loss: 556.1199951171875\n",
            "Epochs: 11/400 ---- Loss: 554.6569213867188\n",
            "Epochs: 12/400 ---- Loss: 553.2030029296875\n",
            "Epochs: 13/400 ---- Loss: 551.7578735351562\n",
            "Epochs: 14/400 ---- Loss: 550.3216552734375\n",
            "Epochs: 15/400 ---- Loss: 548.8941650390625\n",
            "Epochs: 16/400 ---- Loss: 547.4757080078125\n",
            "Epochs: 17/400 ---- Loss: 546.06591796875\n",
            "Epochs: 18/400 ---- Loss: 544.664794921875\n",
            "Epochs: 19/400 ---- Loss: 543.2723388671875\n",
            "Epochs: 20/400 ---- Loss: 541.8885498046875\n",
            "Epochs: 21/400 ---- Loss: 540.5128784179688\n",
            "Epochs: 22/400 ---- Loss: 539.1461181640625\n",
            "Epochs: 23/400 ---- Loss: 537.7876586914062\n",
            "Epochs: 24/400 ---- Loss: 536.4376220703125\n",
            "Epochs: 25/400 ---- Loss: 535.095703125\n",
            "Epochs: 26/400 ---- Loss: 533.76220703125\n",
            "Epochs: 27/400 ---- Loss: 532.4369506835938\n",
            "Epochs: 28/400 ---- Loss: 531.1197509765625\n",
            "Epochs: 29/400 ---- Loss: 529.810791015625\n",
            "Epochs: 30/400 ---- Loss: 528.5099487304688\n",
            "Epochs: 31/400 ---- Loss: 527.2169189453125\n",
            "Epochs: 32/400 ---- Loss: 525.9320068359375\n",
            "Epochs: 33/400 ---- Loss: 524.6550903320312\n",
            "Epochs: 34/400 ---- Loss: 523.3858642578125\n",
            "Epochs: 35/400 ---- Loss: 522.12451171875\n",
            "Epochs: 36/400 ---- Loss: 520.8709716796875\n",
            "Epochs: 37/400 ---- Loss: 519.625\n",
            "Epochs: 38/400 ---- Loss: 518.3870239257812\n",
            "Epochs: 39/400 ---- Loss: 517.1564331054688\n",
            "Epochs: 40/400 ---- Loss: 515.9334716796875\n",
            "Epochs: 41/400 ---- Loss: 514.718017578125\n",
            "Epochs: 42/400 ---- Loss: 513.5101928710938\n",
            "Epochs: 43/400 ---- Loss: 512.3096923828125\n",
            "Epochs: 44/400 ---- Loss: 511.1166076660156\n",
            "Epochs: 45/400 ---- Loss: 509.93084716796875\n",
            "Epochs: 46/400 ---- Loss: 508.75238037109375\n",
            "Epochs: 47/400 ---- Loss: 507.58123779296875\n",
            "Epochs: 48/400 ---- Loss: 506.417236328125\n",
            "Epochs: 49/400 ---- Loss: 505.26043701171875\n",
            "Epochs: 50/400 ---- Loss: 504.11083984375\n",
            "Epochs: 51/400 ---- Loss: 502.9681701660156\n",
            "Epochs: 52/400 ---- Loss: 501.83258056640625\n",
            "Epochs: 53/400 ---- Loss: 500.70404052734375\n",
            "Epochs: 54/400 ---- Loss: 499.58251953125\n",
            "Epochs: 55/400 ---- Loss: 498.46783447265625\n",
            "Epochs: 56/400 ---- Loss: 497.35986328125\n",
            "Epochs: 57/400 ---- Loss: 496.25909423828125\n",
            "Epochs: 58/400 ---- Loss: 495.16473388671875\n",
            "Epochs: 59/400 ---- Loss: 494.077392578125\n",
            "Epochs: 60/400 ---- Loss: 492.9964904785156\n",
            "Epochs: 61/400 ---- Loss: 491.9224548339844\n",
            "Epochs: 62/400 ---- Loss: 490.85491943359375\n",
            "Epochs: 63/400 ---- Loss: 489.7940368652344\n",
            "Epochs: 64/400 ---- Loss: 488.73956298828125\n",
            "Epochs: 65/400 ---- Loss: 487.69171142578125\n",
            "Epochs: 66/400 ---- Loss: 486.650146484375\n",
            "Epochs: 67/400 ---- Loss: 485.6151428222656\n",
            "Epochs: 68/400 ---- Loss: 484.58648681640625\n",
            "Epochs: 69/400 ---- Loss: 483.564208984375\n",
            "Epochs: 70/400 ---- Loss: 482.548095703125\n",
            "Epochs: 71/400 ---- Loss: 481.53839111328125\n",
            "Epochs: 72/400 ---- Loss: 480.5348205566406\n",
            "Epochs: 73/400 ---- Loss: 479.53729248046875\n",
            "Epochs: 74/400 ---- Loss: 478.54608154296875\n",
            "Epochs: 75/400 ---- Loss: 477.56109619140625\n",
            "Epochs: 76/400 ---- Loss: 476.58184814453125\n",
            "Epochs: 77/400 ---- Loss: 475.60888671875\n",
            "Epochs: 78/400 ---- Loss: 474.64178466796875\n",
            "Epochs: 79/400 ---- Loss: 473.6806640625\n",
            "Epochs: 80/400 ---- Loss: 472.7254943847656\n",
            "Epochs: 81/400 ---- Loss: 471.77618408203125\n",
            "Epochs: 82/400 ---- Loss: 470.83270263671875\n",
            "Epochs: 83/400 ---- Loss: 469.89501953125\n",
            "Epochs: 84/400 ---- Loss: 468.96307373046875\n",
            "Epochs: 85/400 ---- Loss: 468.036865234375\n",
            "Epochs: 86/400 ---- Loss: 467.11639404296875\n",
            "Epochs: 87/400 ---- Loss: 466.2015686035156\n",
            "Epochs: 88/400 ---- Loss: 465.29248046875\n",
            "Epochs: 89/400 ---- Loss: 464.388916015625\n",
            "Epochs: 90/400 ---- Loss: 463.4908752441406\n",
            "Epochs: 91/400 ---- Loss: 462.59832763671875\n",
            "Epochs: 92/400 ---- Loss: 461.71136474609375\n",
            "Epochs: 93/400 ---- Loss: 460.829833984375\n",
            "Epochs: 94/400 ---- Loss: 459.95379638671875\n",
            "Epochs: 95/400 ---- Loss: 459.0830078125\n",
            "Epochs: 96/400 ---- Loss: 458.2176208496094\n",
            "Epochs: 97/400 ---- Loss: 457.35760498046875\n",
            "Epochs: 98/400 ---- Loss: 456.5028381347656\n",
            "Epochs: 99/400 ---- Loss: 455.6533203125\n",
            "Epochs: 100/400 ---- Loss: 454.80902099609375\n",
            "Epochs: 101/400 ---- Loss: 453.96990966796875\n",
            "Epochs: 102/400 ---- Loss: 453.13604736328125\n",
            "Epochs: 103/400 ---- Loss: 452.3072814941406\n",
            "Epochs: 104/400 ---- Loss: 451.48358154296875\n",
            "Epochs: 105/400 ---- Loss: 450.66497802734375\n",
            "Epochs: 106/400 ---- Loss: 449.8514709472656\n",
            "Epochs: 107/400 ---- Loss: 449.042724609375\n",
            "Epochs: 108/400 ---- Loss: 448.2391662597656\n",
            "Epochs: 109/400 ---- Loss: 447.4404296875\n",
            "Epochs: 110/400 ---- Loss: 446.6468200683594\n",
            "Epochs: 111/400 ---- Loss: 445.85791015625\n",
            "Epochs: 112/400 ---- Loss: 445.0738220214844\n",
            "Epochs: 113/400 ---- Loss: 444.2947692871094\n",
            "Epochs: 114/400 ---- Loss: 443.520263671875\n",
            "Epochs: 115/400 ---- Loss: 442.7505798339844\n",
            "Epochs: 116/400 ---- Loss: 441.98577880859375\n",
            "Epochs: 117/400 ---- Loss: 441.22552490234375\n",
            "Epochs: 118/400 ---- Loss: 440.47003173828125\n",
            "Epochs: 119/400 ---- Loss: 439.71905517578125\n",
            "Epochs: 120/400 ---- Loss: 438.97296142578125\n",
            "Epochs: 121/400 ---- Loss: 438.23114013671875\n",
            "Epochs: 122/400 ---- Loss: 437.4939880371094\n",
            "Epochs: 123/400 ---- Loss: 436.76141357421875\n",
            "Epochs: 124/400 ---- Loss: 436.0332946777344\n",
            "Epochs: 125/400 ---- Loss: 435.30975341796875\n",
            "Epochs: 126/400 ---- Loss: 434.59051513671875\n",
            "Epochs: 127/400 ---- Loss: 433.87579345703125\n",
            "Epochs: 128/400 ---- Loss: 433.1653747558594\n",
            "Epochs: 129/400 ---- Loss: 432.45947265625\n",
            "Epochs: 130/400 ---- Loss: 431.7578125\n",
            "Epochs: 131/400 ---- Loss: 431.0604553222656\n",
            "Epochs: 132/400 ---- Loss: 430.36737060546875\n",
            "Epochs: 133/400 ---- Loss: 429.6785583496094\n",
            "Epochs: 134/400 ---- Loss: 428.9940490722656\n",
            "Epochs: 135/400 ---- Loss: 428.3136291503906\n",
            "Epochs: 136/400 ---- Loss: 427.637451171875\n",
            "Epochs: 137/400 ---- Loss: 426.96551513671875\n",
            "Epochs: 138/400 ---- Loss: 426.29766845703125\n",
            "Epochs: 139/400 ---- Loss: 425.6338806152344\n",
            "Epochs: 140/400 ---- Loss: 424.97412109375\n",
            "Epochs: 141/400 ---- Loss: 424.31854248046875\n",
            "Epochs: 142/400 ---- Loss: 423.6668395996094\n",
            "Epochs: 143/400 ---- Loss: 423.019287109375\n",
            "Epochs: 144/400 ---- Loss: 422.37567138671875\n",
            "Epochs: 145/400 ---- Loss: 421.73590087890625\n",
            "Epochs: 146/400 ---- Loss: 421.10003662109375\n",
            "Epochs: 147/400 ---- Loss: 420.4681701660156\n",
            "Epochs: 148/400 ---- Loss: 419.84027099609375\n",
            "Epochs: 149/400 ---- Loss: 419.21600341796875\n",
            "Epochs: 150/400 ---- Loss: 418.595947265625\n",
            "Epochs: 151/400 ---- Loss: 417.9793395996094\n",
            "Epochs: 152/400 ---- Loss: 417.36676025390625\n",
            "Epochs: 153/400 ---- Loss: 416.75787353515625\n",
            "Epochs: 154/400 ---- Loss: 416.152587890625\n",
            "Epochs: 155/400 ---- Loss: 415.55108642578125\n",
            "Epochs: 156/400 ---- Loss: 414.95330810546875\n",
            "Epochs: 157/400 ---- Loss: 414.359130859375\n",
            "Epochs: 158/400 ---- Loss: 413.7687072753906\n",
            "Epochs: 159/400 ---- Loss: 413.18182373046875\n",
            "Epochs: 160/400 ---- Loss: 412.5986328125\n",
            "Epochs: 161/400 ---- Loss: 412.01904296875\n",
            "Epochs: 162/400 ---- Loss: 411.44287109375\n",
            "Epochs: 163/400 ---- Loss: 410.87030029296875\n",
            "Epochs: 164/400 ---- Loss: 410.30126953125\n",
            "Epochs: 165/400 ---- Loss: 409.7357482910156\n",
            "Epochs: 166/400 ---- Loss: 409.1736755371094\n",
            "Epochs: 167/400 ---- Loss: 408.6151123046875\n",
            "Epochs: 168/400 ---- Loss: 408.0598449707031\n",
            "Epochs: 169/400 ---- Loss: 407.508056640625\n",
            "Epochs: 170/400 ---- Loss: 406.9595642089844\n",
            "Epochs: 171/400 ---- Loss: 406.4147033691406\n",
            "Epochs: 172/400 ---- Loss: 405.8728942871094\n",
            "Epochs: 173/400 ---- Loss: 405.33447265625\n",
            "Epochs: 174/400 ---- Loss: 404.7994689941406\n",
            "Epochs: 175/400 ---- Loss: 404.2676696777344\n",
            "Epochs: 176/400 ---- Loss: 403.7391662597656\n",
            "Epochs: 177/400 ---- Loss: 403.21392822265625\n",
            "Epochs: 178/400 ---- Loss: 402.6918029785156\n",
            "Epochs: 179/400 ---- Loss: 402.1729431152344\n",
            "Epochs: 180/400 ---- Loss: 401.65716552734375\n",
            "Epochs: 181/400 ---- Loss: 401.1446533203125\n",
            "Epochs: 182/400 ---- Loss: 400.63543701171875\n",
            "Epochs: 183/400 ---- Loss: 400.1290588378906\n",
            "Epochs: 184/400 ---- Loss: 399.6258544921875\n",
            "Epochs: 185/400 ---- Loss: 399.1260070800781\n",
            "Epochs: 186/400 ---- Loss: 398.62890625\n",
            "Epochs: 187/400 ---- Loss: 398.135009765625\n",
            "Epochs: 188/400 ---- Loss: 397.64404296875\n",
            "Epochs: 189/400 ---- Loss: 397.15618896484375\n",
            "Epochs: 190/400 ---- Loss: 396.6712341308594\n",
            "Epochs: 191/400 ---- Loss: 396.1892395019531\n",
            "Epochs: 192/400 ---- Loss: 395.7102966308594\n",
            "Epochs: 193/400 ---- Loss: 395.2342224121094\n",
            "Epochs: 194/400 ---- Loss: 394.7610778808594\n",
            "Epochs: 195/400 ---- Loss: 394.2908935546875\n",
            "Epochs: 196/400 ---- Loss: 393.8236083984375\n",
            "Epochs: 197/400 ---- Loss: 393.35906982421875\n",
            "Epochs: 198/400 ---- Loss: 392.8974609375\n",
            "Epochs: 199/400 ---- Loss: 392.438720703125\n",
            "Epochs: 200/400 ---- Loss: 391.9826354980469\n",
            "Epochs: 201/400 ---- Loss: 391.5294494628906\n",
            "Epochs: 202/400 ---- Loss: 391.0790100097656\n",
            "Epochs: 203/400 ---- Loss: 390.6313781738281\n",
            "Epochs: 204/400 ---- Loss: 390.1864318847656\n",
            "Epochs: 205/400 ---- Loss: 389.74432373046875\n",
            "Epochs: 206/400 ---- Loss: 389.3047790527344\n",
            "Epochs: 207/400 ---- Loss: 388.86798095703125\n",
            "Epochs: 208/400 ---- Loss: 388.43389892578125\n",
            "Epochs: 209/400 ---- Loss: 388.00238037109375\n",
            "Epochs: 210/400 ---- Loss: 387.5735778808594\n",
            "Epochs: 211/400 ---- Loss: 387.1474609375\n",
            "Epochs: 212/400 ---- Loss: 386.7238464355469\n",
            "Epochs: 213/400 ---- Loss: 386.3028259277344\n",
            "Epochs: 214/400 ---- Loss: 385.88446044921875\n",
            "Epochs: 215/400 ---- Loss: 385.46856689453125\n",
            "Epochs: 216/400 ---- Loss: 385.0552673339844\n",
            "Epochs: 217/400 ---- Loss: 384.64459228515625\n",
            "Epochs: 218/400 ---- Loss: 384.2362060546875\n",
            "Epochs: 219/400 ---- Loss: 383.83056640625\n",
            "Epochs: 220/400 ---- Loss: 383.42724609375\n",
            "Epochs: 221/400 ---- Loss: 383.02655029296875\n",
            "Epochs: 222/400 ---- Loss: 382.62823486328125\n",
            "Epochs: 223/400 ---- Loss: 382.23223876953125\n",
            "Epochs: 224/400 ---- Loss: 381.83880615234375\n",
            "Epochs: 225/400 ---- Loss: 381.4477233886719\n",
            "Epochs: 226/400 ---- Loss: 381.0589599609375\n",
            "Epochs: 227/400 ---- Loss: 380.6727294921875\n",
            "Epochs: 228/400 ---- Loss: 380.2888488769531\n",
            "Epochs: 229/400 ---- Loss: 379.90716552734375\n",
            "Epochs: 230/400 ---- Loss: 379.5279235839844\n",
            "Epochs: 231/400 ---- Loss: 379.1510925292969\n",
            "Epochs: 232/400 ---- Loss: 378.7763671875\n",
            "Epochs: 233/400 ---- Loss: 378.40423583984375\n",
            "Epochs: 234/400 ---- Loss: 378.0340576171875\n",
            "Epochs: 235/400 ---- Loss: 377.666259765625\n",
            "Epochs: 236/400 ---- Loss: 377.30072021484375\n",
            "Epochs: 237/400 ---- Loss: 376.9373779296875\n",
            "Epochs: 238/400 ---- Loss: 376.57635498046875\n",
            "Epochs: 239/400 ---- Loss: 376.217529296875\n",
            "Epochs: 240/400 ---- Loss: 375.86077880859375\n",
            "Epochs: 241/400 ---- Loss: 375.50634765625\n",
            "Epochs: 242/400 ---- Loss: 375.154052734375\n",
            "Epochs: 243/400 ---- Loss: 374.8038635253906\n",
            "Epochs: 244/400 ---- Loss: 374.4557800292969\n",
            "Epochs: 245/400 ---- Loss: 374.1098327636719\n",
            "Epochs: 246/400 ---- Loss: 373.76611328125\n",
            "Epochs: 247/400 ---- Loss: 373.4244079589844\n",
            "Epochs: 248/400 ---- Loss: 373.0848388671875\n",
            "Epochs: 249/400 ---- Loss: 372.7473449707031\n",
            "Epochs: 250/400 ---- Loss: 372.4118347167969\n",
            "Epochs: 251/400 ---- Loss: 372.0784606933594\n",
            "Epochs: 252/400 ---- Loss: 371.74713134765625\n",
            "Epochs: 253/400 ---- Loss: 371.417724609375\n",
            "Epochs: 254/400 ---- Loss: 371.0903625488281\n",
            "Epochs: 255/400 ---- Loss: 370.7650146484375\n",
            "Epochs: 256/400 ---- Loss: 370.44171142578125\n",
            "Epochs: 257/400 ---- Loss: 370.1203308105469\n",
            "Epochs: 258/400 ---- Loss: 369.80096435546875\n",
            "Epochs: 259/400 ---- Loss: 369.4835510253906\n",
            "Epochs: 260/400 ---- Loss: 369.1679992675781\n",
            "Epochs: 261/400 ---- Loss: 368.85443115234375\n",
            "Epochs: 262/400 ---- Loss: 368.54278564453125\n",
            "Epochs: 263/400 ---- Loss: 368.23297119140625\n",
            "Epochs: 264/400 ---- Loss: 367.9251403808594\n",
            "Epochs: 265/400 ---- Loss: 367.61907958984375\n",
            "Epochs: 266/400 ---- Loss: 367.31500244140625\n",
            "Epochs: 267/400 ---- Loss: 367.0127868652344\n",
            "Epochs: 268/400 ---- Loss: 366.7123107910156\n",
            "Epochs: 269/400 ---- Loss: 366.4136962890625\n",
            "Epochs: 270/400 ---- Loss: 366.11700439453125\n",
            "Epochs: 271/400 ---- Loss: 365.82208251953125\n",
            "Epochs: 272/400 ---- Loss: 365.52886962890625\n",
            "Epochs: 273/400 ---- Loss: 365.23748779296875\n",
            "Epochs: 274/400 ---- Loss: 364.9480285644531\n",
            "Epochs: 275/400 ---- Loss: 364.66015625\n",
            "Epochs: 276/400 ---- Loss: 364.37408447265625\n",
            "Epochs: 277/400 ---- Loss: 364.08984375\n",
            "Epochs: 278/400 ---- Loss: 363.8071594238281\n",
            "Epochs: 279/400 ---- Loss: 363.52642822265625\n",
            "Epochs: 280/400 ---- Loss: 363.2472839355469\n",
            "Epochs: 281/400 ---- Loss: 362.9698486328125\n",
            "Epochs: 282/400 ---- Loss: 362.69403076171875\n",
            "Epochs: 283/400 ---- Loss: 362.41998291015625\n",
            "Epochs: 284/400 ---- Loss: 362.14764404296875\n",
            "Epochs: 285/400 ---- Loss: 361.876953125\n",
            "Epochs: 286/400 ---- Loss: 361.60784912109375\n",
            "Epochs: 287/400 ---- Loss: 361.34033203125\n",
            "Epochs: 288/400 ---- Loss: 361.0745849609375\n",
            "Epochs: 289/400 ---- Loss: 360.81036376953125\n",
            "Epochs: 290/400 ---- Loss: 360.5478820800781\n",
            "Epochs: 291/400 ---- Loss: 360.28692626953125\n",
            "Epochs: 292/400 ---- Loss: 360.02752685546875\n",
            "Epochs: 293/400 ---- Loss: 359.76971435546875\n",
            "Epochs: 294/400 ---- Loss: 359.51348876953125\n",
            "Epochs: 295/400 ---- Loss: 359.2587890625\n",
            "Epochs: 296/400 ---- Loss: 359.0057067871094\n",
            "Epochs: 297/400 ---- Loss: 358.7541198730469\n",
            "Epochs: 298/400 ---- Loss: 358.50408935546875\n",
            "Epochs: 299/400 ---- Loss: 358.25555419921875\n",
            "Epochs: 300/400 ---- Loss: 358.0086364746094\n",
            "Epochs: 301/400 ---- Loss: 357.76312255859375\n",
            "Epochs: 302/400 ---- Loss: 357.5190124511719\n",
            "Epochs: 303/400 ---- Loss: 357.276611328125\n",
            "Epochs: 304/400 ---- Loss: 357.0354919433594\n",
            "Epochs: 305/400 ---- Loss: 356.7958984375\n",
            "Epochs: 306/400 ---- Loss: 356.55792236328125\n",
            "Epochs: 307/400 ---- Loss: 356.3211364746094\n",
            "Epochs: 308/400 ---- Loss: 356.0859680175781\n",
            "Epochs: 309/400 ---- Loss: 355.85223388671875\n",
            "Epochs: 310/400 ---- Loss: 355.61993408203125\n",
            "Epochs: 311/400 ---- Loss: 355.3889465332031\n",
            "Epochs: 312/400 ---- Loss: 355.1593322753906\n",
            "Epochs: 313/400 ---- Loss: 354.9313049316406\n",
            "Epochs: 314/400 ---- Loss: 354.7044372558594\n",
            "Epochs: 315/400 ---- Loss: 354.47906494140625\n",
            "Epochs: 316/400 ---- Loss: 354.25518798828125\n",
            "Epochs: 317/400 ---- Loss: 354.032470703125\n",
            "Epochs: 318/400 ---- Loss: 353.8111572265625\n",
            "Epochs: 319/400 ---- Loss: 353.5913391113281\n",
            "Epochs: 320/400 ---- Loss: 353.3726806640625\n",
            "Epochs: 321/400 ---- Loss: 353.1553955078125\n",
            "Epochs: 322/400 ---- Loss: 352.9395446777344\n",
            "Epochs: 323/400 ---- Loss: 352.72491455078125\n",
            "Epochs: 324/400 ---- Loss: 352.5115661621094\n",
            "Epochs: 325/400 ---- Loss: 352.2995910644531\n",
            "Epochs: 326/400 ---- Loss: 352.0888366699219\n",
            "Epochs: 327/400 ---- Loss: 351.8792724609375\n",
            "Epochs: 328/400 ---- Loss: 351.67120361328125\n",
            "Epochs: 329/400 ---- Loss: 351.4642028808594\n",
            "Epochs: 330/400 ---- Loss: 351.25860595703125\n",
            "Epochs: 331/400 ---- Loss: 351.05413818359375\n",
            "Epochs: 332/400 ---- Loss: 350.8509826660156\n",
            "Epochs: 333/400 ---- Loss: 350.649169921875\n",
            "Epochs: 334/400 ---- Loss: 350.4483947753906\n",
            "Epochs: 335/400 ---- Loss: 350.2489013671875\n",
            "Epochs: 336/400 ---- Loss: 350.05059814453125\n",
            "Epochs: 337/400 ---- Loss: 349.85357666015625\n",
            "Epochs: 338/400 ---- Loss: 349.6576843261719\n",
            "Epochs: 339/400 ---- Loss: 349.4630432128906\n",
            "Epochs: 340/400 ---- Loss: 349.26959228515625\n",
            "Epochs: 341/400 ---- Loss: 349.0771484375\n",
            "Epochs: 342/400 ---- Loss: 348.88604736328125\n",
            "Epochs: 343/400 ---- Loss: 348.6961364746094\n",
            "Epochs: 344/400 ---- Loss: 348.5072021484375\n",
            "Epochs: 345/400 ---- Loss: 348.31951904296875\n",
            "Epochs: 346/400 ---- Loss: 348.1330871582031\n",
            "Epochs: 347/400 ---- Loss: 347.9474792480469\n",
            "Epochs: 348/400 ---- Loss: 347.7633056640625\n",
            "Epochs: 349/400 ---- Loss: 347.58013916015625\n",
            "Epochs: 350/400 ---- Loss: 347.3981018066406\n",
            "Epochs: 351/400 ---- Loss: 347.21710205078125\n",
            "Epochs: 352/400 ---- Loss: 347.03717041015625\n",
            "Epochs: 353/400 ---- Loss: 346.8584289550781\n",
            "Epochs: 354/400 ---- Loss: 346.68072509765625\n",
            "Epochs: 355/400 ---- Loss: 346.50421142578125\n",
            "Epochs: 356/400 ---- Loss: 346.32855224609375\n",
            "Epochs: 357/400 ---- Loss: 346.154296875\n",
            "Epochs: 358/400 ---- Loss: 345.9808654785156\n",
            "Epochs: 359/400 ---- Loss: 345.8084716796875\n",
            "Epochs: 360/400 ---- Loss: 345.6371154785156\n",
            "Epochs: 361/400 ---- Loss: 345.4669189453125\n",
            "Epochs: 362/400 ---- Loss: 345.29766845703125\n",
            "Epochs: 363/400 ---- Loss: 345.1293640136719\n",
            "Epochs: 364/400 ---- Loss: 344.9623107910156\n",
            "Epochs: 365/400 ---- Loss: 344.7960510253906\n",
            "Epochs: 366/400 ---- Loss: 344.6308898925781\n",
            "Epochs: 367/400 ---- Loss: 344.4667053222656\n",
            "Epochs: 368/400 ---- Loss: 344.303466796875\n",
            "Epochs: 369/400 ---- Loss: 344.1413269042969\n",
            "Epochs: 370/400 ---- Loss: 343.98016357421875\n",
            "Epochs: 371/400 ---- Loss: 343.81988525390625\n",
            "Epochs: 372/400 ---- Loss: 343.6606750488281\n",
            "Epochs: 373/400 ---- Loss: 343.50238037109375\n",
            "Epochs: 374/400 ---- Loss: 343.3450927734375\n",
            "Epochs: 375/400 ---- Loss: 343.18865966796875\n",
            "Epochs: 376/400 ---- Loss: 343.0332946777344\n",
            "Epochs: 377/400 ---- Loss: 342.878662109375\n",
            "Epochs: 378/400 ---- Loss: 342.7252502441406\n",
            "Epochs: 379/400 ---- Loss: 342.5725402832031\n",
            "Epochs: 380/400 ---- Loss: 342.4208679199219\n",
            "Epochs: 381/400 ---- Loss: 342.27001953125\n",
            "Epochs: 382/400 ---- Loss: 342.12017822265625\n",
            "Epochs: 383/400 ---- Loss: 341.97125244140625\n",
            "Epochs: 384/400 ---- Loss: 341.82318115234375\n",
            "Epochs: 385/400 ---- Loss: 341.6759948730469\n",
            "Epochs: 386/400 ---- Loss: 341.5297546386719\n",
            "Epochs: 387/400 ---- Loss: 341.38427734375\n",
            "Epochs: 388/400 ---- Loss: 341.2398376464844\n",
            "Epochs: 389/400 ---- Loss: 341.0962219238281\n",
            "Epochs: 390/400 ---- Loss: 340.9534606933594\n",
            "Epochs: 391/400 ---- Loss: 340.8114929199219\n",
            "Epochs: 392/400 ---- Loss: 340.67047119140625\n",
            "Epochs: 393/400 ---- Loss: 340.5302734375\n",
            "Epochs: 394/400 ---- Loss: 340.39093017578125\n",
            "Epochs: 395/400 ---- Loss: 340.25238037109375\n",
            "Epochs: 396/400 ---- Loss: 340.11468505859375\n",
            "Epochs: 397/400 ---- Loss: 339.9779357910156\n",
            "Epochs: 398/400 ---- Loss: 339.84185791015625\n",
            "Epochs: 399/400 ---- Loss: 339.7066650390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ojQ1jPV0X5K",
        "outputId": "874bee92-224e-4f8d-9f4f-1312cc274391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 41.3948,  80.3929],\n",
              "        [ 55.8980,  52.1113],\n",
              "        [ 78.9178, 120.3097],\n",
              "        [ 33.5588,  37.9318],\n",
              "        [106.3680, 124.0656]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBWfzYv_06v_",
        "outputId": "e4285468-359a-46ce-be84-1c2d68070846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 32.,  66.],\n",
              "        [ 52.,  76.],\n",
              "        [102., 155.],\n",
              "        [ 32.,  26.],\n",
              "        [ 99., 100.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Torch built in function"
      ],
      "metadata": {
        "id": "6VZxCTiS6dFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "PQn_0mjv08uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [74, 66, 43],\n",
        "                   [91, 87, 65],\n",
        "                   [88, 134, 59],\n",
        "                   [101, 44, 37],\n",
        "                   [68, 96, 71],\n",
        "                   [73, 66, 44],\n",
        "                   [92, 87, 64],\n",
        "                   [87, 135, 57],\n",
        "                   [103, 43, 36],\n",
        "                   [68, 97, 70]],\n",
        "                  dtype='float32')\n",
        "\n",
        "\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119],\n",
        "                    [57, 69],\n",
        "                    [80, 102],\n",
        "                    [118, 132],\n",
        "                    [21, 38],\n",
        "                    [104, 118],\n",
        "                    [57, 69],\n",
        "                    [82, 100],\n",
        "                    [118, 134],\n",
        "                    [20, 38],\n",
        "                    [102, 120]],\n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "DITMQbsa65yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkD0Tv-37q9J",
        "outputId": "a3e96bb6-d7d2-4871-ca69-4dbcac4e52b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([73., 67., 43.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader\n",
        "\n",
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "q63F3OZk7LQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBV83zYg7hxg",
        "outputId": "05e96a3e-851d-4771-b119-a86392e677d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 5\n",
        "train_data = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "NGwiwxz771Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for xb, yb in train_data:\n",
        "  print(xb)\n",
        "  print(yb)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a79YqL18nPF",
        "outputId": "3867da82-0136-4cb1-fbe9-7b76a746e248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 68.,  97.,  70.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [103.,  43.,  36.]])\n",
            "tensor([[102., 120.],\n",
            "        [ 57.,  69.],\n",
            "        [119., 133.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##nn.linear\n",
        "\n",
        "#define model\n",
        "\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJUoatSr86IV",
        "outputId": "36435610-4bd9-4fc0-90e2-50b61c61e899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.5687,  0.5513, -0.0236],\n",
            "        [-0.1820,  0.3206, -0.0346]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0323, -0.0153], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3rOPOL999Dx",
        "outputId": "3300ff2e-7606-412b-affe-e33f2b9ccada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.5687,  0.5513, -0.0236],\n",
              "         [-0.1820,  0.3206, -0.0346]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0323, -0.0153], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZGhROKZ-FNO",
        "outputId": "b70884d7-7024-479b-9964-a094c272975e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 77.4749,   6.6924],\n",
              "        [ 98.7950,   9.4226],\n",
              "        [122.0220,  25.1041],\n",
              "        [ 80.8778,  -6.0703],\n",
              "        [ 90.5521,  15.7825],\n",
              "        [ 77.4923,   6.1899],\n",
              "        [ 98.2201,   9.0674],\n",
              "        [122.5671,  24.8875],\n",
              "        [ 80.8604,  -5.5678],\n",
              "        [ 89.9598,  15.9299],\n",
              "        [ 76.9000,   6.3372],\n",
              "        [ 98.8124,   8.9201],\n",
              "        [122.5968,  25.4593],\n",
              "        [ 81.4701,  -6.2176],\n",
              "        [ 90.5347,  16.2850]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_fn = F.mse_loss"
      ],
      "metadata": {
        "id": "8-a1vdxd-z3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(preds, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkikleiO-9Yl",
        "outputId": "7d7501a5-cd60-4bfa-9d07-d251b85803a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4106.7529, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr = 1e-5)"
      ],
      "metadata": {
        "id": "XPlKQcf3_Ecq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "def fit(num_epochs, model, loss_fn, opt, train_data):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for xb, yb in train_data:\n",
        "      pred = model(xb)\n",
        "      loss = loss_fn(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 ==0:\n",
        "      print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss))\n",
        "\n"
      ],
      "metadata": {
        "id": "G6CkH3nH_0cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(100, model, loss_fn, opt, train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfSR-qkAAFCL",
        "outputId": "3c7aa800-322f-4449-fa26-75125b0ab594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 507.1291\n",
            "Epoch [20/100], Loss: 177.8215\n",
            "Epoch [30/100], Loss: 225.3439\n",
            "Epoch [40/100], Loss: 127.4318\n",
            "Epoch [50/100], Loss: 186.5381\n",
            "Epoch [60/100], Loss: 74.9179\n",
            "Epoch [70/100], Loss: 39.6480\n",
            "Epoch [80/100], Loss: 31.3548\n",
            "Epoch [90/100], Loss: 32.8377\n",
            "Epoch [100/100], Loss: 34.0096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(inputs)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsHnfIEoAGBY",
        "outputId": "ae282e6d-80f7-45c5-f9a8-ad452c78efe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.4098,  71.2553],\n",
              "        [ 78.9191,  97.3858],\n",
              "        [122.4140, 138.2805],\n",
              "        [ 29.2668,  42.6291],\n",
              "        [ 91.5565, 110.1911],\n",
              "        [ 57.2773,  70.1945],\n",
              "        [ 78.1434,  96.8742],\n",
              "        [122.4119, 138.5737],\n",
              "        [ 30.3994,  43.6899],\n",
              "        [ 91.9134, 110.7402],\n",
              "        [ 57.6341,  70.7437],\n",
              "        [ 77.7865,  96.3250],\n",
              "        [123.1897, 138.7921],\n",
              "        [ 28.9100,  42.0799],\n",
              "        [ 92.6891, 111.2519]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h54T0X2pB7DF",
        "outputId": "3f1c6312-ff41-4320-a5f4-689f88228d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([[75,66,44.]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awsqnlgiB9Yy",
        "outputId": "4b56fa12-6b7c-4fe0-e3d9-430092f1091c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[57.2752, 70.4877]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pred.to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "18xLDNtWDCsy",
        "outputId": "0ff42f18-3497-417a-da9d-2df2e38092e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a3e6010dd70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'to_numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "gtxOssQqDIpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "KCX1GAY5COJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model_weights.pth')"
      ],
      "metadata": {
        "id": "1ihHmE-yDu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([[75,66,44.]]))"
      ],
      "metadata": {
        "id": "aEyEyRQHD2k6",
        "outputId": "9291431a-9f1f-490c-f083-294d7e4769ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-0888b9f84915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m44.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8oZhjRMD4UI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}